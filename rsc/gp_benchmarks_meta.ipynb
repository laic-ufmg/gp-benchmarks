{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:33:36.518433Z",
     "start_time": "2018-03-09T21:33:36.474612Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "\n",
    "from math import sqrt, sin, cos, log, pi, e\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.fitness import make_fitness\n",
    "from sklearn.model_selection import KFold\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import os\n",
    "# Change the current folder to the folder where we can find the results\n",
    "cur_dir_path = !pwd\n",
    "os.chdir(cur_dir_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis pre-running\n",
    "## Comparing function times (used by GP)\n",
    "Just to have an idea of the time spent by functions (from a possible function set) inside GP. Notice that we analyzed the functions as they are implemented by `gplearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:14:11.368930Z",
     "start_time": "2018-03-09T21:14:09.288912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin time:        0.2238\n",
      "Cos time:        0.2639\n",
      "Log time:        0.6882\n",
      "Sqrt time:       0.0888\n",
      "Prot. div time:  0.3603\n",
      "AQ time:         0.2060\n",
      "Mul time:        0.0635\n",
      "Sub time:        0.0630\n",
      "Add time:        0.0581\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "fmt = \"{:<17}{:.4f}\"\n",
    "print(fmt.format(\"Sin time:\",\n",
    "                 timeit.timeit(stmt=\"[np.sin(x) for x in X]\", \n",
    "                                      setup=\"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000)\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Cos time:\", \n",
    "                 timeit.timeit(stmt=\"[np.cos(x) for x in X]\", \n",
    "                                      setup=\"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000)\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Log time:\", \n",
    "                 timeit.timeit(stmt=\"[_protected_log(x) for x in X]\", \n",
    "                                      setup=\"from gplearn.functions import _protected_log;\"\n",
    "                                      \"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000)\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Sqrt time:\", \n",
    "                 timeit.timeit(stmt=\"[_protected_sqrt(x) for x in X]\", \n",
    "                                      setup=\"from gplearn.functions import _protected_sqrt;\"\n",
    "                                      \"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000)\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Prot. div time:\", \n",
    "                 timeit.timeit(stmt=\"[_protected_division(x,y) for x,y in zip(X,Y)]\", \n",
    "                                      setup=\"from gplearn.functions import _protected_division;\"\n",
    "                                      \"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000);\"\n",
    "                                      \"Y = np.random.rand(1,1000);\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"AQ time:\", \n",
    "                 timeit.timeit(stmt=\"[np.divide(x, np.sqrt(1+y**2)) for x,y in zip(X,Y)]\", \n",
    "                                      setup=\"from gplearn.functions import _protected_division;\"\n",
    "                                      \"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000);\"\n",
    "                                      \"Y = np.random.rand(1,1000);\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Mul time:\", \n",
    "                 timeit.timeit(stmt=\"[np.multiply(x,y) for x,y in zip(X,Y)]\", \n",
    "                                      setup=\"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000);\"\n",
    "                                      \"Y = np.random.rand(1,1000);\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Sub time:\", \n",
    "                 timeit.timeit(stmt=\"[np.subtract(x,y) for x,y in zip(X,Y)]\", \n",
    "                                      setup=\"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000);\"\n",
    "                                      \"Y = np.random.rand(1,1000);\", \n",
    "                                      number = 10000)))\n",
    "print(fmt.format(\"Add time:\",\n",
    "                 timeit.timeit(stmt=\"[np.add(x,y) for x,y in zip(X,Y)]\", \n",
    "                                      setup=\"import numpy as np;\"\n",
    "                                      \"X = np.random.rand(1,1000);\"\n",
    "                                      \"Y = np.random.rand(1,1000);\", \n",
    "                                      number = 10000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Datasets\n",
    "## Generating synthetic data\n",
    "Synthetic data is generated from equations, for a given input space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:14:35.020572Z",
     "start_time": "2018-03-09T21:14:19.212407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the \"Meier-3\" dataset\n",
      "Generating the \"Meier-4\" dataset\n",
      "Generating the \"Nonic\" dataset\n",
      "Generating the \"Sine\" dataset\n",
      "Generating the \"Burks\" dataset\n",
      "Generating the \"R1\" dataset\n",
      "Generating the \"R2\" dataset\n",
      "Generating the \"R3\" dataset\n",
      "Generating the \"Poly-10\" dataset\n",
      "Generating the \"Koza-2\" dataset\n",
      "Generating the \"Koza-3\" dataset\n",
      "Generating the \"Korns-1\" dataset\n",
      "Generating the \"Korns-4\" dataset\n",
      "Generating the \"Korns-7\" dataset\n",
      "Generating the \"Korns-11\" dataset\n",
      "Generating the \"Korns-12\" dataset\n",
      "Generating the \"Vladislavleva-1\" dataset\n",
      "Generating the \"Vladislavleva-2\" dataset\n",
      "Generating the \"Vladislavleva-3\" dataset\n",
      "Generating the \"Vladislavleva-4\" dataset\n",
      "Generating the \"Vladislavleva-5\" dataset\n",
      "Generating the \"Vladislavleva-6\" dataset\n",
      "Generating the \"Vladislavleva-7\" dataset\n",
      "Generating the \"Vladislavleva-8\" dataset\n",
      "Generating the \"Pagie-1\" dataset\n",
      "Generating the \"Keijzer-1\" dataset\n",
      "Generating the \"Keijzer-2\" dataset\n",
      "Generating the \"Keijzer-3\" dataset\n",
      "Generating the \"Keijzer-4\" dataset\n",
      "Generating the \"Keijzer-5\" dataset\n",
      "Generating the \"Keijzer-6\" dataset\n",
      "Generating the \"Keijzer-7\" dataset\n",
      "Generating the \"Keijzer-8\" dataset\n",
      "Generating the \"Keijzer-9\" dataset\n",
      "Generating the \"Keijzer-10\" dataset\n",
      "Generating the \"Keijzer-11\" dataset\n",
      "Generating the \"Keijzer-12\" dataset\n",
      "Generating the \"Keijzer-13\" dataset\n",
      "Generating the \"Keijzer-14\" dataset\n",
      "Generating the \"Keijzer-15\" dataset\n",
      "Generating the \"Nguyen-1\" dataset\n",
      "Generating the \"Nguyen-2\" dataset\n",
      "Generating the \"Nguyen-3\" dataset\n",
      "Generating the \"Nguyen-4\" dataset\n",
      "Generating the \"Nguyen-5\" dataset\n",
      "Generating the \"Nguyen-6\" dataset\n",
      "Generating the \"Nguyen-7\" dataset\n",
      "Generating the \"Nguyen-8\" dataset\n",
      "Generating the \"Nguyen-9\" dataset\n",
      "Generating the \"Nguyen-10\" dataset\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.RandomState(seed)\n",
    "\n",
    "def synthetic_gen(name, rnd, function, training_gen, test_gen=None):\n",
    "    print(\"Generating the \\\"\" + name + \"\\\" dataset\")\n",
    "    training_set = []\n",
    "    test_set = []\n",
    "    for i in range(training_gen.n):\n",
    "        inst = training_gen.generate(rnd)\n",
    "        training_set.append(inst + [function(*inst)])\n",
    "    if test_gen:\n",
    "        for i in range(test_gen.n):\n",
    "            inst = test_gen.generate(rnd)\n",
    "            test_set.append(inst + [function(*inst)])\n",
    "    else:\n",
    "        test_set = training_set\n",
    "    return {\"training\": pd.DataFrame(training_set),\n",
    "            \"test\": pd.DataFrame(test_set)}\n",
    "\n",
    "class U:\n",
    "    def __init__(self, ini, end, n):\n",
    "        self.ini = ini\n",
    "        self.end = end\n",
    "        self.n = n\n",
    "    \n",
    "    def generate(self, rnd):\n",
    "        return [rnd.uniform(ini, end) for ini, end in zip(self.ini, self.end)]\n",
    "\n",
    "class E:\n",
    "    def __init__(self, ini, end, step):\n",
    "        self.ini = ini\n",
    "        self.end = end\n",
    "        self.step = step\n",
    "        \n",
    "        mesh = np.meshgrid(*[np.arange(ini, end+step, step) \n",
    "                           for ini, end, step in zip(self.ini, self.end, self.step)])\n",
    "        self.points = [dim.reshape(1,-1)[0] for dim in mesh]\n",
    "        self.index = 0\n",
    "        self.n = len(self.points[0])\n",
    "    \n",
    "    def generate(self, rnd):\n",
    "        inst = [self.points[i][self.index] for i in range(len(self.points))]\n",
    "        self.index += 1\n",
    "        return inst\n",
    "    \n",
    "data_synt = {\"meier-3\": synthetic_gen(\"Meier-3\", rnd, \n",
    "                                      lambda x_1,x_2: (x_1**2*x_2**2)/(x_1+x_2), \n",
    "                                      U([-1, -1], [1, 1], 50), U([-1, -1], [1, 1], 50)),\n",
    "            \"meier-4\": synthetic_gen(\"Meier-4\", rnd, \n",
    "                                     lambda x_1,x_2: x_1**5/x_2**3, \n",
    "                                     U([-1, -1], [1, 1], 50), U([-1, -1], [1, 1], 50)),\n",
    "            \"nonic\": synthetic_gen(\"Nonic\", rnd,\n",
    "                                   lambda x_1: sum([x_1**i for i in range(1,10)]), \n",
    "                                   E([-1], [1], [2/19]), U([-1], [1], 20)),\n",
    "            \"sine\": synthetic_gen(\"Sine\", rnd,\n",
    "                                  lambda x_1: sin(x_1), \n",
    "                                  E([0], [6.2], [0.1])),\n",
    "            \"burks\": synthetic_gen(\"Burks\", rnd,\n",
    "                                   lambda x_1: 4*x_1**4 + 3*x_1**3 + 2*x_1**2 + x_1, \n",
    "                                   U([-1], [1], 20)),\n",
    "            \"r1\": synthetic_gen(\"R1\", rnd,\n",
    "                                lambda x_1: (x_1+1)**3/(x_1**2-x_1+1), \n",
    "                                E([-1], [1], [2/19]), U([-1], [1], 20)),\n",
    "            \"r2\": synthetic_gen(\"R2\", rnd,\n",
    "                                lambda x_1: (x_1**5-3*x_1**3+1)/(x_1**2+1), \n",
    "                                E([-1], [1], [2/19]), U([-1], [1], 20)),\n",
    "            \"r3\": synthetic_gen(\"R3\", rnd,\n",
    "                                lambda x_1: (x_1**6+x_1**5)/(x_1**4+x_1**3+x_1**2+x_1+1), \n",
    "                                E([-1], [1], [2/19]), U([-1], [1], 20)),\n",
    "            \"poly-10\": synthetic_gen(\"Poly-10\", rnd,\n",
    "                                     lambda x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10: \n",
    "                                         x_1*x_2+x_3*x_4+x_5*x_6+x_1*x_7*x_9+x_3*x_6*x_10,\n",
    "                                     U([0]*10, [1]*10, 330), U([0]*10, [1]*10, 170)),\n",
    "            \"koza-2\": synthetic_gen(\"Koza-2\", rnd,\n",
    "                                    lambda x_1: x_1**5-2*x_1**3+x_1, \n",
    "                                    U([-1], [1], 20), U([-1], [1], 20)),\n",
    "            \"koza-3\": synthetic_gen(\"Koza-3\", rnd,\n",
    "                                    lambda x_1: x_1**6-2*x_1**4+x_1**2,\n",
    "                                    U([-1], [1], 20), U([-1], [1], 20)),\n",
    "            \"korns-1\": synthetic_gen(\"Korns-1\", rnd,\n",
    "                                     lambda x_1, x_2, x_3, x_4, x_5: 1.57+24.3*x_4,\n",
    "                                     U([-50]*5, [50]*5, 10000), U([-50]*5, [50]*5, 10000)),\n",
    "            \"korns-4\": synthetic_gen(\"Korns-4\", rnd,\n",
    "                                     lambda x_1, x_2, x_3, x_4, x_5: \n",
    "                                         -2.3+0.13*sin(x_3),\n",
    "                                     U([-50]*5, [50]*5, 10000), U([-50]*5, [50]*5, 10000)),\n",
    "            \"korns-7\": synthetic_gen(\"Korns-7\", rnd,\n",
    "                                     lambda x_1, x_2, x_3, x_4, x_5: \n",
    "                                         213.80940889*(1-e**(-0.54723748542*x_1)),\n",
    "                                     U([-50]*5, [50]*5, 10000), U([-50]*5, [50]*5, 10000)),\n",
    "            \"korns-11\": synthetic_gen(\"Korns-11\", rnd,\n",
    "                                     lambda x_1, x_2, x_3, x_4, x_5: \n",
    "                                         6.87+11*cos(7.23*x_1**3),\n",
    "                                     U([-50]*5, [50]*5, 10000), U([-50]*5, [50]*5, 10000)),\n",
    "            \"korns-12\": synthetic_gen(\"Korns-12\", rnd,\n",
    "                                     lambda x_1, x_2, x_3, x_4, x_5: \n",
    "                                         2-2.1*cos(9.8*x_1)*sin(1.3*x_5),\n",
    "                                     U([-50]*5, [50]*5, 10000), U([-50]*5, [50]*5, 10000)),\n",
    "            \"vladislavleva-1\": synthetic_gen(\"Vladislavleva-1\", rnd,\n",
    "                                             lambda x_1, x_2: \n",
    "                                                 e**(-(x_1-1)**2)/(1.2+(x_2-2.5)**2),\n",
    "                                             U([0.3]*2, [4]*2, 100), E([-0.2]*2, [4.2]*2, [0.1]*2)),\n",
    "            \"vladislavleva-2\": synthetic_gen(\"Vladislavleva-2\", rnd,\n",
    "                                             lambda x_1: \n",
    "                                                 e**(-x_1)*x_1**3*(cos(x_1)*sin(x_1))*(cos(x_1)*sin(x_1)**2-1),\n",
    "                                             E([0.05], [10], [0.1]), E([-0.5], [10.5], [0.05])),\n",
    "            \"vladislavleva-3\": synthetic_gen(\"Vladislavleva-3\", rnd,\n",
    "                                             lambda x_1, x_2: \n",
    "                                                 e**(-x_1)*x_1**3*(cos(x_1)*sin(x_1))*(cos(x_1)*sin(x_1)**2-1)*(x_2-5),\n",
    "                                             E([0.05]*2, [10, 10.05], [0.1, 2]), E([-0.5]*2, [10.5]*2, [0.05, 0.5])),\n",
    "            \"vladislavleva-4\": synthetic_gen(\"Vladislavleva-4\", rnd,\n",
    "                                             lambda x_1, x_2, x_3, x_4, x_5: \n",
    "                                                 10/(5+(x_1-3)**2+(x_2-3)**2+(x_3-3)**2+(x_4-3)**2+(x_5-3)**2),\n",
    "                                             U([0.05]*5, [6.05]*5, 1024), U([-0.25]*5, [6.35]*5, 5000)),\n",
    "            \"vladislavleva-5\": synthetic_gen(\"Vladislavleva-5\", rnd,\n",
    "                                             lambda x_1, x_2, x_3: \n",
    "                                                 30*(x_1-1)*(x_3-1)/((x_1-10)*x_2**2),\n",
    "                                             U([0.05, 1, 0.05], [2]*3, 300), \n",
    "                                             E([-0.05, 0.95, -0.05], [2.1, 2.05, 2.1], [0.15, 0.1, 0.15])),\n",
    "            \"vladislavleva-6\": synthetic_gen(\"Vladislavleva-6\", rnd,\n",
    "                                             lambda x_1, x_2: 6*sin(x_1)*cos(x_2),\n",
    "                                             U([0.1]*2, [5.9]*5, 30), \n",
    "                                             E([-0.05]*2, [6.05]*2, [0.02]*2)),\n",
    "            \"vladislavleva-7\": synthetic_gen(\"Vladislavleva-7\", rnd,\n",
    "                                             lambda x_1, x_2: \n",
    "                                                 (x_1-3)*(x_2-3)+2*sin((x_1-4)*(x_2-4)),\n",
    "                                             U([0.05]*2, [6.05]*2, 300), U([-0.25]*2, [6.35]*2, 1000)),\n",
    "            \"vladislavleva-8\": synthetic_gen(\"Vladislavleva-8\", rnd,\n",
    "                                             lambda x_1, x_2: \n",
    "                                                 ((x_1-3)**4+(x_2-3)**3-(x_2-3))/((x_2-2)**4+10),\n",
    "                                             U([0.05]*2, [6.05]*2, 50), E([-0.25]*2, [6.35]*2, [0.2]*2)),\n",
    "            \"pagie-1\": synthetic_gen(\"Pagie-1\", rnd,\n",
    "                                     lambda x_1, x_2: 1/(1+x_1**(-4))+1/(1+x_2**(-4)),\n",
    "                                     E([-5]*2, [5]*2, [0.4]*2)),\n",
    "            \"keijzer-1\": synthetic_gen(\"Keijzer-1\", rnd,\n",
    "                                       lambda x_1: \n",
    "                                           0.3*x_1*sin(2*pi*x_1),\n",
    "                                       E([-1], [1], [0.1]),\n",
    "                                       E([-1], [1], [0.001])),\n",
    "            \"keijzer-2\": synthetic_gen(\"Keijzer-2\", rnd,\n",
    "                                       lambda x_1: \n",
    "                                           0.3*x_1*sin(2*pi*x_1),\n",
    "                                       E([-2], [2], [0.1]),\n",
    "                                       E([-2], [2], [0.001])),\n",
    "            \"keijzer-3\": synthetic_gen(\"Keijzer-3\", rnd,\n",
    "                                       lambda x_1: \n",
    "                                           0.3*x_1*sin(2*pi*x_1),\n",
    "                                       E([-3], [3], [0.1]),\n",
    "                                       E([-3], [3], [0.001])),\n",
    "            \"keijzer-4\": synthetic_gen(\"Keijzer-4\", rnd,\n",
    "                                       lambda x_1: \n",
    "                                           x_1**3*e**(-x_1)*cos(x_1)*sin(x_1)*(sin(x_1)**2*cos(x_1)-1),\n",
    "                                       E([0], [10], [0.05]),\n",
    "                                       E([0.05], [10.05], [0.05])),\n",
    "            \"keijzer-5\": synthetic_gen(\"Keijzer-5\", rnd,\n",
    "                                       lambda x_1, x_2, x_3: 30*x_1*x_3/((x_1-10)*x_2**2),\n",
    "                                       U([-1, 1, -1], [1,2,1], 1000),\n",
    "                                       U([-1, 1, -1], [1,2,1], 10000)),\n",
    "            \"keijzer-6\": synthetic_gen(\"Keijzer-6\", rnd,\n",
    "                                       lambda x_1: sum([1/i for i in range(1, x_1+1)]),\n",
    "                                       E([1], [50], [1]),\n",
    "                                       E([1], [120], [1])),\n",
    "            \"keijzer-7\": synthetic_gen(\"Keijzer-7\", rnd,\n",
    "                                       lambda x_1: log(x_1),\n",
    "                                       E([1], [100], [1]),\n",
    "                                       E([1], [100], [0.1])),\n",
    "            \"keijzer-8\": synthetic_gen(\"Keijzer-8\", rnd,\n",
    "                                       lambda x_1: sqrt(x_1),\n",
    "                                       E([0], [100], [1]),\n",
    "                                       E([0], [100], [0.1])),\n",
    "            \"keijzer-9\": synthetic_gen(\"Keijzer-9\", rnd,\n",
    "                                       lambda x_1: log(x_1+sqrt(x_1**2+1)),\n",
    "                                       E([0], [100], [1]),\n",
    "                                       E([0], [100], [0.1])),\n",
    "            \"keijzer-10\": synthetic_gen(\"Keijzer-10\", rnd,\n",
    "                                       lambda x_1, x_2: x_1**x_2,\n",
    "                                       U([0]*2, [1]*2, 100),\n",
    "                                       E([0]*2, [1]*2, [0.01]*2)),\n",
    "            \"keijzer-11\": synthetic_gen(\"Keijzer-11\", rnd,\n",
    "                                       lambda x_1, x_2: x_1*x_2+sin((x_1-1)*(x_2-1)),\n",
    "                                       U([-3]*2, [3]*2, 20),\n",
    "                                       E([-3]*2, [3]*2, [0.01]*2)),\n",
    "            \"keijzer-12\": synthetic_gen(\"Keijzer-12\", rnd,\n",
    "                                       lambda x_1, x_2: x_1**4-x_1**3+(x_2**2/2)-x_2,\n",
    "                                       U([-3]*2, [3]*2, 20),\n",
    "                                       E([-3]*2, [3]*2, [0.01]*2)),\n",
    "            \"keijzer-13\": synthetic_gen(\"Keijzer-13\", rnd,\n",
    "                                       lambda x_1, x_2: 6*sin(x_1)*cos(x_2),\n",
    "                                       U([-3]*2, [3]*2, 20),\n",
    "                                       E([-3]*2, [3]*2, [0.01]*2)),\n",
    "            \"keijzer-14\": synthetic_gen(\"Keijzer-14\", rnd,\n",
    "                                       lambda x_1, x_2: 8/(2+x_1**2+x_2**2),\n",
    "                                       U([-3]*2, [3]*2, 20),\n",
    "                                       E([-3]*2, [3]*2, [0.01]*2)),\n",
    "            \"keijzer-15\": synthetic_gen(\"Keijzer-15\", rnd,\n",
    "                                       lambda x_1, x_2: (x_1**3/5)+(x_2**3/2)-x_2-x_1,\n",
    "                                       U([-3]*2, [3]*2, 20),\n",
    "                                       E([-3]*2, [3]*2, [0.01]*2)),\n",
    "            \"nguyen-1\": synthetic_gen(\"Nguyen-1\", rnd,\n",
    "                                       lambda x_1: x_1**3+x_1**2+x_1,\n",
    "                                       U([-1], [1], 20),\n",
    "                                       U([-1], [1], 20)),\n",
    "            \"nguyen-2\": synthetic_gen(\"Nguyen-2\", rnd,\n",
    "                                       lambda x_1: x_1**4+x_1**3+x_1**2+x_1,\n",
    "                                       U([-1], [1], 20),\n",
    "                                       U([-1], [1], 20)),\n",
    "            \"nguyen-3\": synthetic_gen(\"Nguyen-3\", rnd,\n",
    "                                       lambda x_1: x_1**5+x_1**4+x_1**3+x_1**2+x_1,\n",
    "                                       U([-1], [1], 20),\n",
    "                                       U([-1], [1], 20)),\n",
    "            \"nguyen-4\": synthetic_gen(\"Nguyen-4\", rnd,\n",
    "                                       lambda x_1: x_1**6+x_1**5+x_1**4+x_1**3+x_1**2+x_1,\n",
    "                                       U([-1], [1], 20),\n",
    "                                       U([-1], [1], 20)),\n",
    "            \"nguyen-5\": synthetic_gen(\"Nguyen-5\", rnd,\n",
    "                                       lambda x_1: sin(x_1**2)*cos(x_1)-1,\n",
    "                                       U([-1], [1], 20),\n",
    "                                       U([-1], [1], 20)),\n",
    "            \"nguyen-6\": synthetic_gen(\"Nguyen-6\", rnd,\n",
    "                                       lambda x_1: sin(x_1)+sin(x_1+x_1**2),\n",
    "                                       U([-1], [1], 20),\n",
    "                                       U([-1], [1], 20)),\n",
    "            \"nguyen-7\": synthetic_gen(\"Nguyen-7\", rnd,\n",
    "                                       lambda x_1: log(x_1+1)+log(x_1**2+1),\n",
    "                                       U([0], [2], 20),\n",
    "                                       U([0], [2], 20)),\n",
    "            \"nguyen-8\": synthetic_gen(\"Nguyen-8\", rnd,\n",
    "                                       lambda x_1: sqrt(x_1),\n",
    "                                       U([0], [4], 20),\n",
    "                                       U([0], [4], 20)),\n",
    "            \"nguyen-9\": synthetic_gen(\"Nguyen-9\", rnd,\n",
    "                                       lambda x_1, x_2: sin(x_1)+sin(x_2**2),\n",
    "                                       U([-1]*2, [1]*2, 100),\n",
    "                                       U([-1]*2, [1]*2, 100)),\n",
    "            \"nguyen-10\": synthetic_gen(\"Nguyen-10\", rnd,\n",
    "                                       lambda x_1, x_2: 2*sin(x_1)*cos(x_2),\n",
    "                                       U([-1]*2, [1]*2, 100),\n",
    "                                       U([-1]*2, [1]*2, 100))\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading real-world datasets\n",
    "\"Real-world\" datasets comprehend datasets obtained from different domains, based on measures of some phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:15:10.790327Z",
     "start_time": "2018-03-09T21:14:35.795053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the \"Abalone\" dataset\n",
      "Reading the \"Airfoil\" dataset\n",
      "Reading the \"Boston\" dataset\n",
      "Reading the \"Combined-cycle\" dataset\n",
      "Reading the \"Computer-hardware\" dataset\n",
      "Reading the \"Concrete-strength\" dataset\n",
      "Reading the \"Energy-cooling\" dataset\n",
      "Reading the \"Energy-heating\" dataset\n",
      "Reading the \"Forest-fire\" dataset\n",
      "Reading the \"Wine-quality-red\" dataset\n",
      "Reading the \"Wine-quality-white\" dataset\n",
      "Reading the \"Yacht\" dataset\n"
     ]
    }
   ],
   "source": [
    "seed = 4567\n",
    "rnd = np.random.RandomState(seed)\n",
    "\n",
    "def get_data(name, url, rnd=None, pd_sep=',', pd_header=None, pd_skiprows=None, dataset=None):\n",
    "    print(\"Reading the \\\"\" + name + \"\\\" dataset\")\n",
    "    if dataset == \"BOH\":\n",
    "        from sklearn.datasets import load_boston\n",
    "        boston = load_boston()\n",
    "        df = pd.DataFrame(boston['data'])\n",
    "        df = pd.concat([df, pd.Series(boston['target'])], axis=1)\n",
    "    elif dataset == \"CCP\":\n",
    "        # Get the file object from an url\n",
    "        r = requests.get(url)\n",
    "        # Create a ZipFile object from it\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        # Read from a xlsx file inside the zip file\n",
    "        df = pd.read_excel(z.open('CCPP/Folds5x2_pp.xlsx'))\n",
    "    elif dataset == \"CST\":\n",
    "        df = pd.read_excel(url)\n",
    "    elif dataset == \"ENC\":\n",
    "        df = pd.read_excel(url)\n",
    "        # Drop Y1\n",
    "        df.drop(\"Y1\", axis=1, inplace=True)\n",
    "    elif dataset == \"ENH\":\n",
    "        df = pd.read_excel(url)\n",
    "        # Drop Y2\n",
    "        df.drop(\"Y2\", axis=1, inplace=True)\n",
    "    elif dataset == \"YAC\":\n",
    "        # Get the data as text\n",
    "        text = requests.get(url).text\n",
    "        # Split in rows (remove the last line)\n",
    "        e_re = re.compile(\"\\s*\\n\\s*\")\n",
    "        rows = e_re.split(text)[:-1]\n",
    "        e_re = re.compile(\" +\")\n",
    "        # Split cells per row\n",
    "        df = pd.DataFrame([e_re.split(row) for row in rows])\n",
    "    else:\n",
    "        df = pd.read_csv(url, header=pd_header, sep=pd_sep, skiprows=pd_skiprows)\n",
    "        if dataset == \"ABA\":\n",
    "            # Get dummy variables for the first column\n",
    "            df_dummies = pd.get_dummies(df.iloc[:,0])\n",
    "            # Drop the first column\n",
    "            df.drop(df.columns[0], axis=1, inplace=True)\n",
    "            # Concatenate the dummy variables with the data\n",
    "            df = pd.concat([df_dummies, df], axis=1)\n",
    "            df = df.sample(500, random_state=rnd, axis=0)\n",
    "        elif dataset == \"CPU\":\n",
    "            # Drop the first two columns\n",
    "            df.drop(df.columns[[0,1]], axis=1, inplace=True)\n",
    "        elif dataset == \"FFR\":\n",
    "            df.drop([\"month\", \"day\"], axis=1, inplace=True)\n",
    "        elif dataset == \"OZO\":\n",
    "            # Imputation (replance NaN's by the mean of the column)\n",
    "            df.fillna(df.mean(), inplace=True)\n",
    "    return df.apply(np.float64)\n",
    "\n",
    "\n",
    "data_real = {\"abalone\": get_data('Abalone', \n",
    "                                 'https://archive.ics.uci.edu/ml/'\n",
    "                                 'machine-learning-databases/abalone/abalone.data',\n",
    "                                 rnd=rnd, dataset='ABA'),\n",
    "            \"airfoil\": get_data('Airfoil',\n",
    "                                'https://archive.ics.uci.edu/ml/'\n",
    "                                'machine-learning-databases/00291/airfoil_self_noise.dat',\n",
    "                                pd_sep=\"\\t\"),\n",
    "            \"boston\": get_data('Boston', \"\", dataset=\"BOH\"),\n",
    "            \"combined-cycle\": get_data('Combined-cycle', \n",
    "                                       'https://archive.ics.uci.edu/ml/'\n",
    "                                       'machine-learning-databases/00294/CCPP.zip',\n",
    "                                       dataset=\"CCP\"),\n",
    "            \"computer-hardware\": get_data('Computer-hardware', \n",
    "                                          'https://archive.ics.uci.edu/ml/'\n",
    "                                          'machine-learning-databases/cpu-performance/machine.data',\n",
    "                                          dataset=\"CPU\"),\n",
    "            \"concrete-strength\": get_data('Concrete-strength', \n",
    "                                          'https://archive.ics.uci.edu/ml/'\n",
    "                                          'machine-learning-databases/concrete/compressive/Concrete_Data.xls',\n",
    "                                          dataset=\"CST\"),\n",
    "            \"energy-cooling\": get_data('Energy-cooling', \n",
    "                                       'http://archive.ics.uci.edu/ml/'\n",
    "                                       'machine-learning-databases/00242/ENB2012_data.xlsx',\n",
    "                                       dataset=\"ENC\"),\n",
    "            \"energy-heating\": get_data('Energy-heating', \n",
    "                                       'http://archive.ics.uci.edu/ml/'\n",
    "                                       'machine-learning-databases/00242/ENB2012_data.xlsx',\n",
    "                                       dataset=\"ENH\"),\n",
    "            \"forest-fire\": get_data('Forest-fire', \n",
    "                                    'https://archive.ics.uci.edu/ml/'\n",
    "                                    'machine-learning-databases/forest-fires/forestfires.csv',\n",
    "                                    pd_header='infer', dataset=\"FFR\"),\n",
    "            \"ozone\": get_data('Ozone', './data/ozone.data', dataset=\"OZO\"),\n",
    "            \"wine-quality-red\": get_data('Wine-quality-red', \n",
    "                                         'https://archive.ics.uci.edu/ml/'\n",
    "                                         'machine-learning-databases/wine-quality/winequality-red.csv',\n",
    "                                         pd_header='infer', pd_sep=';'),\n",
    "            \"wine-quality-white\": get_data('Wine-quality-white', \n",
    "                                           'https://archive.ics.uci.edu/ml/'\n",
    "                                           'machine-learning-databases/wine-quality/winequality-white.csv', \n",
    "                                           pd_header='infer', pd_sep=';'),\n",
    "            \"yacht\": get_data('Yacht', 'https://archive.ics.uci.edu/ml/'\n",
    "                              'machine-learning-databases/00243/yacht_hydrodynamics.data', dataset=\"YAC\")\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating GP performance in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _aq(x1, x2):\n",
    "    return np.divide(x1, np.sqrt(1 + x2**2))   \n",
    "\n",
    "aq = make_function(function=_aq,\n",
    "                   name='aq',\n",
    "                   arity=2)\n",
    "\n",
    "def evaluate(dataset_lst, n_jobs=None, n_rep=30, cv=None):\n",
    "    stats = {}\n",
    "    experiments = []\n",
    "    seed = 1234\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=rnd)\n",
    "    \n",
    "    for data_name, data_points in dataset_lst.items():\n",
    "        stats[data_name] = {}\n",
    "        # Reset the pseudo-random number generator for each dataset (used by GP)\n",
    "        rnd = np.random.RandomState(seed)\n",
    "        \n",
    "        if cv is not None: \n",
    "            partitions = list(kf.split(data_points))\n",
    "        \n",
    "        for i in range(n_rep):\n",
    "            if cv is not None: \n",
    "                training = data_points.iloc[partitions[i % cv][0],:]\n",
    "                test = data_points.iloc[partitions[i % cv][1],:]\n",
    "            else:\n",
    "                training = data_points['training']\n",
    "                test = data_points['test']\n",
    "            experiments.append([data_name, i+1, training, test, rnd.randint(10**6)])\n",
    "    if not n_jobs or n_jobs > 1:    \n",
    "        with Pool(processes=n_jobs) as pool:\n",
    "            for exec_stats in pool.imap(worker, experiments):\n",
    "                data_name = exec_stats[0]\n",
    "                for stats_name, stats_value in exec_stats[1].items():\n",
    "                    if stats_name not in stats[data_name]:\n",
    "                        stats[data_name][stats_name] = []\n",
    "                    stats[data_name][stats_name].append(stats_value)\n",
    "    else:\n",
    "        for experiment in experiments:\n",
    "            exec_stats = worker(experiment)\n",
    "            data_name = exec_stats[0]\n",
    "            for stats_name, stats_value in exec_stats[1].items():\n",
    "                if stats_name not in stats[data_name]:\n",
    "                    stats[data_name][stats_name] = []\n",
    "                stats[data_name][stats_name].append(stats_value)\n",
    "    return stats\n",
    "\n",
    "def worker(param):\n",
    "    print(\"Dataset \\\"\" + param[0] + \"\\\", exec.\", param[1])\n",
    "    return [param[0], run_gp(training=param[2], test=param[3], rnd=param[4])]\n",
    "\n",
    "def run_gp(training, test, rnd=None):\n",
    "    # Normalization constant used to compute the normalized RMSE\n",
    "    norm_const = np.sqrt(training.shape[0]/(training.shape[0]-1))/training.iloc[:,-1].std()\n",
    "    \n",
    "    # Genetic programming instance used to perform symbolic regression in the datasets\n",
    "    function_set = ['add', 'sub', 'mul', aq, 'sqrt', 'sin']\n",
    "    gp_param = {'population_size': 1000,\n",
    "                  'generations': 50, \n",
    "                  'stopping_criteria': 0.00,\n",
    "                  'const_range': (-1,1),\n",
    "                  'init_depth': (2,6),\n",
    "                  'init_method': 'half and half',\n",
    "                  'metric': make_fitness(function=lambda y, y_pred, w:\n",
    "                      np.sqrt(np.average(((y_pred - y) ** 2), weights=w)) * norm_const,\n",
    "                                           greater_is_better=False),\n",
    "                  'tournament_size': 10,\n",
    "                  'p_crossover': 0.85, \n",
    "                  'function_set': function_set,\n",
    "                  'p_subtree_mutation': 0.05,\n",
    "                  'p_hoist_mutation': 0.05, \n",
    "                  'p_point_mutation': 0.05,\n",
    "                  'max_samples': 1, \n",
    "                  'verbose': 0,\n",
    "                  'parsimony_coefficient': 0.001, \n",
    "                  'random_state': rnd,\n",
    "                  'n_jobs': 1}\n",
    "    est_gp = SymbolicRegressor(**gp_param)\n",
    "    est_gp.fit(training.iloc[:,:-1], training.iloc[:,-1])\n",
    "    \n",
    "    #norm_const = np.sqrt(training.shape[0]/(training.shape[0]-1))/training.iloc[:,-1].std()\n",
    "    stats = {'size': est_gp._program.length_,\n",
    "             'tr_rmse': est_gp._program.raw_fitness_ / norm_const,\n",
    "             'tr_nrmse': est_gp._program.raw_fitness_}\n",
    "    y_est = est_gp.predict(test.iloc[:,:-1])\n",
    "    rmse = np.sqrt(np.average((y_est - test.iloc[:,-1]) ** 2))\n",
    "    norm_const = np.sqrt(test.shape[0]/(test.shape[0]-1))/test.iloc[:,-1].std()\n",
    "    \n",
    "    stats['ts_rmse'] = rmse\n",
    "    stats['ts_nrmse'] = rmse * norm_const\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def write_stats(stats_dict, path='./performace_metrics/'):\n",
    "    \"\"\"Write statistics returned by worker/run_gp methods.\n",
    "\n",
    "    Extended description of function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stats_dict : dict\n",
    "        A dictionary containing results from different datasets. The format is\n",
    "        in the form stats_dict['data_set_name']['statistics_name']\n",
    "    arg2 : str\n",
    "        Description of arg2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Description of return value\n",
    "    \"\"\"\n",
    "    for key, data in stats_dict.items():\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(path + key + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running GP for each dataset\n",
    "This stage should take a few hours. That is why the results are saved in a local folder future accesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:16:43.993406Z",
     "start_time": "2018-03-09T21:16:43.482566Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_synt = evaluate(data_synt, n_rep = 30)\n",
    "write_stats(stats_synt)\n",
    "\n",
    "# The real-word dataset is evaluated using cross-validation\n",
    "stats_real = evaluate(data_real, n_rep = 30, cv = 5)\n",
    "write_stats(stats_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = {}\n",
    "for key, data in data_synt.items():\n",
    "    meta_data[key] = {}\n",
    "    meta_data[key]['tr_n_inst'] = data['training'].shape[0]\n",
    "    meta_data[key]['tr_n_feat'] = data['training'].shape[1] - 1\n",
    "    \n",
    "    meta_data[key]['ts_n_inst'] = data['training'].shape[0]\n",
    "    \n",
    "path = './performace_metrics/'\n",
    "for file in os.listdir(path):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:32:43.460145Z",
     "start_time": "2018-03-09T21:32:43.440704Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T21:32:50.119205Z",
     "start_time": "2018-03-09T21:32:50.112183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/luiz/Dados/Trabalho/Pesquisa/luiz_otavio_operador_semantico/publicacoes/2018/GECCO-GP-Benchmarks/rsc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
